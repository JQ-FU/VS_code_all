{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 60000\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader,TensorDataset,random_split,SubsetRandomSampler, ConcatDataset\n",
    "from torch.nn import functional as F\n",
    "import torchvision\n",
    "from torchvision import datasets,transforms\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# 加载 MNIST 数据集\n",
    "train_dataset = torchvision.datasets.MNIST('classifier_data', train=True, download=True)\n",
    "test_dataset = torchvision.datasets.MNIST('classifier_data', train=False, download=True)\n",
    "\n",
    "# 定义数据转换\n",
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# 应用转换到数据集\n",
    "train_dataset.transform = transform\n",
    "test_dataset.transform = transform\n",
    "\n",
    "# 获取训练数据的样本数\n",
    "m = len(train_dataset)\n",
    "\n",
    "# 示例打印样本数\n",
    "print(f'Number of training samples: {m}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SCNNB(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SCNNB, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1,32,kernel_size=(3,3))\n",
    "        self.BN1 = nn.BatchNorm2d(32,False)\n",
    "        self.pooling1 = nn.MaxPool2d(2,2)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(32,64,kernel_size=(3,3))\n",
    "        self.BN2 = nn.BatchNorm2d(64,False)\n",
    "        self.pooling2 = nn.MaxPool2d(2,2)\n",
    "\n",
    "        self.fc1 = nn.Linear(1600,1280)\n",
    "        self.fc2 = nn.Linear(1280,10)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        #print('第零层',x.shape)\n",
    "        x = self.pooling1(F.relu(self.BN1(self.conv1(x))))\n",
    "        #print('第一层',x.shape)\n",
    "        x = self.pooling2(F.relu(self.BN2(self.conv2(x))))\n",
    "        #print('第二层',x.shape)\n",
    "        x = x.reshape(-1,1600)\n",
    "        #print('第三层',x.shape)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, 0.5)\n",
    "        x = self.fc2(x)  # 将 dropout 放在 fc1 后\n",
    "        #print(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.manual_seed(42)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "dataset = ConcatDataset([train_dataset, test_dataset])\n",
    "num_epochs=10\n",
    "batch_size=128\n",
    "k=10\n",
    "splits=KFold(n_splits=k,shuffle=True,random_state=42)\n",
    "foldperf={} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model,device,dataloader,loss_fn,optimizer):\n",
    "  train_loss,train_correct=0.0,0\n",
    "  model.train()\n",
    "  for images, labels in dataloader:\n",
    "    images,labels = images.to(device),labels.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    output = model(images)\n",
    "    \n",
    "   \n",
    "    loss = loss_fn(output,labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    train_loss += loss.item() * images.size(0)\n",
    "    scores, predictions = torch.max(output.data, 1)\n",
    "    \n",
    "    train_correct += (predictions == labels).sum().item()\n",
    "  return train_loss,train_correct\n",
    "def valid_epoch(model,device,dataloader,loss_fn):\n",
    "        valid_loss, val_correct = 0.0, 0\n",
    "        model.eval()\n",
    "        for images, labels in dataloader:\n",
    "            images,labels = images.to(device),labels.to(device)\n",
    "            output = model(images)\n",
    "            loss=loss_fn(output,labels)\n",
    "            valid_loss+=loss.item()*images.size(0)\n",
    "            scores, predictions = torch.max(output.data,1)\n",
    "            val_correct+=(predictions == labels).sum().item()\n",
    "        return valid_loss,val_correct "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "train_loss type: <class 'float'>, train_correct type: <class 'int'>\n",
      "Epoch:1/10 AVG Training Loss:0.191 AVG Test Loss:0.091 AVG Training Acc 94.51 % AVG Test Acc 97.49 %\n",
      "train_loss type: <class 'float'>, train_correct type: <class 'int'>\n",
      "Epoch:2/10 AVG Training Loss:0.068 AVG Test Loss:0.074 AVG Training Acc 97.88 % AVG Test Acc 97.80 %\n",
      "train_loss type: <class 'float'>, train_correct type: <class 'int'>\n",
      "Epoch:3/10 AVG Training Loss:0.051 AVG Test Loss:0.060 AVG Training Acc 98.45 % AVG Test Acc 98.29 %\n",
      "train_loss type: <class 'float'>, train_correct type: <class 'int'>\n",
      "Epoch:4/10 AVG Training Loss:0.039 AVG Test Loss:0.052 AVG Training Acc 98.75 % AVG Test Acc 98.46 %\n",
      "train_loss type: <class 'float'>, train_correct type: <class 'int'>\n",
      "Epoch:5/10 AVG Training Loss:0.033 AVG Test Loss:0.043 AVG Training Acc 98.98 % AVG Test Acc 98.59 %\n",
      "train_loss type: <class 'float'>, train_correct type: <class 'int'>\n",
      "Epoch:6/10 AVG Training Loss:0.026 AVG Test Loss:0.045 AVG Training Acc 99.16 % AVG Test Acc 98.60 %\n",
      "train_loss type: <class 'float'>, train_correct type: <class 'int'>\n",
      "Epoch:7/10 AVG Training Loss:0.025 AVG Test Loss:0.042 AVG Training Acc 99.21 % AVG Test Acc 98.67 %\n",
      "train_loss type: <class 'float'>, train_correct type: <class 'int'>\n",
      "Epoch:8/10 AVG Training Loss:0.021 AVG Test Loss:0.037 AVG Training Acc 99.36 % AVG Test Acc 98.87 %\n",
      "train_loss type: <class 'float'>, train_correct type: <class 'int'>\n",
      "Epoch:9/10 AVG Training Loss:0.018 AVG Test Loss:0.050 AVG Training Acc 99.40 % AVG Test Acc 98.70 %\n",
      "train_loss type: <class 'float'>, train_correct type: <class 'int'>\n",
      "Epoch:10/10 AVG Training Loss:0.018 AVG Test Loss:0.040 AVG Training Acc 99.42 % AVG Test Acc 98.90 %\n",
      "Fold 2\n",
      "train_loss type: <class 'float'>, train_correct type: <class 'int'>\n",
      "Epoch:1/10 AVG Training Loss:0.189 AVG Test Loss:0.076 AVG Training Acc 94.74 % AVG Test Acc 97.67 %\n",
      "train_loss type: <class 'float'>, train_correct type: <class 'int'>\n",
      "Epoch:2/10 AVG Training Loss:0.067 AVG Test Loss:0.071 AVG Training Acc 97.93 % AVG Test Acc 97.79 %\n",
      "train_loss type: <class 'float'>, train_correct type: <class 'int'>\n",
      "Epoch:3/10 AVG Training Loss:0.050 AVG Test Loss:0.056 AVG Training Acc 98.47 % AVG Test Acc 98.50 %\n",
      "train_loss type: <class 'float'>, train_correct type: <class 'int'>\n",
      "Epoch:4/10 AVG Training Loss:0.039 AVG Test Loss:0.050 AVG Training Acc 98.80 % AVG Test Acc 98.43 %\n",
      "train_loss type: <class 'float'>, train_correct type: <class 'int'>\n",
      "Epoch:5/10 AVG Training Loss:0.034 AVG Test Loss:0.040 AVG Training Acc 98.97 % AVG Test Acc 98.79 %\n",
      "train_loss type: <class 'float'>, train_correct type: <class 'int'>\n",
      "Epoch:6/10 AVG Training Loss:0.027 AVG Test Loss:0.045 AVG Training Acc 99.12 % AVG Test Acc 98.67 %\n",
      "train_loss type: <class 'float'>, train_correct type: <class 'int'>\n",
      "Epoch:7/10 AVG Training Loss:0.024 AVG Test Loss:0.044 AVG Training Acc 99.25 % AVG Test Acc 98.71 %\n",
      "train_loss type: <class 'float'>, train_correct type: <class 'int'>\n",
      "Epoch:8/10 AVG Training Loss:0.022 AVG Test Loss:0.038 AVG Training Acc 99.31 % AVG Test Acc 98.89 %\n",
      "train_loss type: <class 'float'>, train_correct type: <class 'int'>\n",
      "Epoch:9/10 AVG Training Loss:0.019 AVG Test Loss:0.043 AVG Training Acc 99.40 % AVG Test Acc 98.79 %\n",
      "train_loss type: <class 'float'>, train_correct type: <class 'int'>\n",
      "Epoch:10/10 AVG Training Loss:0.016 AVG Test Loss:0.037 AVG Training Acc 99.50 % AVG Test Acc 98.96 %\n",
      "Fold 3\n",
      "train_loss type: <class 'float'>, train_correct type: <class 'int'>\n",
      "Epoch:1/10 AVG Training Loss:0.195 AVG Test Loss:0.094 AVG Training Acc 94.66 % AVG Test Acc 97.17 %\n",
      "train_loss type: <class 'float'>, train_correct type: <class 'int'>\n",
      "Epoch:2/10 AVG Training Loss:0.070 AVG Test Loss:0.070 AVG Training Acc 97.86 % AVG Test Acc 97.81 %\n",
      "train_loss type: <class 'float'>, train_correct type: <class 'int'>\n",
      "Epoch:3/10 AVG Training Loss:0.053 AVG Test Loss:0.055 AVG Training Acc 98.39 % AVG Test Acc 98.39 %\n",
      "train_loss type: <class 'float'>, train_correct type: <class 'int'>\n",
      "Epoch:4/10 AVG Training Loss:0.038 AVG Test Loss:0.056 AVG Training Acc 98.84 % AVG Test Acc 98.40 %\n",
      "train_loss type: <class 'float'>, train_correct type: <class 'int'>\n",
      "Epoch:5/10 AVG Training Loss:0.033 AVG Test Loss:0.045 AVG Training Acc 99.02 % AVG Test Acc 98.63 %\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m history \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_loss\u001b[39m\u001b[38;5;124m'\u001b[39m: [], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_loss\u001b[39m\u001b[38;5;124m'\u001b[39m: [],\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_acc\u001b[39m\u001b[38;5;124m'\u001b[39m:[],\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_acc\u001b[39m\u001b[38;5;124m'\u001b[39m:[]}\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m---> 15\u001b[0m     train_loss, train_correct\u001b[38;5;241m=\u001b[39m\u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_loss type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(train_loss)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, train_correct type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(train_correct)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     17\u001b[0m     test_loss, test_correct\u001b[38;5;241m=\u001b[39mvalid_epoch(model,device,test_loader,criterion)\n",
      "Cell \u001b[1;32mIn[4], line 4\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[1;34m(model, device, dataloader, loss_fn, optimizer)\u001b[0m\n\u001b[0;32m      2\u001b[0m train_loss,train_correct\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m,\u001b[38;5;241m0\u001b[39m\n\u001b[0;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m images, labels \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[0;32m      5\u001b[0m   images,labels \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(device),labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m      6\u001b[0m   optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32md:\\anaconda\\envs\\DL\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32md:\\anaconda\\envs\\DL\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:673\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    672\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 673\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    675\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32md:\\anaconda\\envs\\DL\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32md:\\anaconda\\envs\\DL\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32md:\\anaconda\\envs\\DL\\lib\\site-packages\\torch\\utils\\data\\dataset.py:350\u001b[0m, in \u001b[0;36mConcatDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    349\u001b[0m     sample_idx \u001b[38;5;241m=\u001b[39m idx \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcumulative_sizes[dataset_idx \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m--> 350\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatasets\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdataset_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43msample_idx\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32md:\\anaconda\\envs\\DL\\lib\\site-packages\\torchvision\\datasets\\mnist.py:146\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    143\u001b[0m img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(img\u001b[38;5;241m.\u001b[39mnumpy(), mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    149\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform(target)\n",
      "File \u001b[1;32md:\\anaconda\\envs\\DL\\lib\\site-packages\\torchvision\\transforms\\transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[1;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[1;32md:\\anaconda\\envs\\DL\\lib\\site-packages\\torchvision\\transforms\\transforms.py:137\u001b[0m, in \u001b[0;36mToTensor.__call__\u001b[1;34m(self, pic)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pic):\n\u001b[0;32m    130\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;124;03m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;124;03m        Tensor: Converted image.\u001b[39;00m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\anaconda\\envs\\DL\\lib\\site-packages\\torchvision\\transforms\\functional.py:174\u001b[0m, in \u001b[0;36mto_tensor\u001b[1;34m(pic)\u001b[0m\n\u001b[0;32m    172\u001b[0m img \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mview(pic\u001b[38;5;241m.\u001b[39msize[\u001b[38;5;241m1\u001b[39m], pic\u001b[38;5;241m.\u001b[39msize[\u001b[38;5;241m0\u001b[39m], F_pil\u001b[38;5;241m.\u001b[39mget_image_num_channels(pic))\n\u001b[0;32m    173\u001b[0m \u001b[38;5;66;03m# put it from HWC to CHW format\u001b[39;00m\n\u001b[1;32m--> 174\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpermute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(img, torch\u001b[38;5;241m.\u001b[39mByteTensor):\n\u001b[0;32m    176\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\u001b[38;5;241m.\u001b[39mto(dtype\u001b[38;5;241m=\u001b[39mdefault_float_dtype)\u001b[38;5;241m.\u001b[39mdiv(\u001b[38;5;241m255\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for fold, (train_idx,val_idx) in enumerate(splits.split(np.arange(len(dataset)))):\n",
    "  print('Fold {}'.format(fold + 1))\n",
    "  train_sampler = SubsetRandomSampler(train_idx)\n",
    "  test_sampler = SubsetRandomSampler(val_idx)\n",
    "  train_loader = DataLoader(dataset, batch_size=batch_size, sampler=train_sampler)\n",
    "  test_loader = DataLoader(dataset, batch_size=batch_size, sampler=test_sampler)\n",
    "\n",
    "  \n",
    "  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "  model = SCNNB()\n",
    "  model.to(device)\n",
    "  optimizer = optim.Adam(model.parameters(), lr=0.002)\n",
    "  history = {'train_loss': [], 'test_loss': [],'train_acc':[],'test_acc':[]}\n",
    "  for epoch in range(num_epochs):\n",
    "      train_loss, train_correct=train_epoch(model,device,train_loader,criterion,optimizer)\n",
    "      print(f'train_loss type: {type(train_loss)}, train_correct type: {type(train_correct)}')\n",
    "      test_loss, test_correct=valid_epoch(model,device,test_loader,criterion)\n",
    "      train_loss = train_loss / len(train_loader.sampler)\n",
    "      train_acc = train_correct / len(train_loader.sampler) * 100\n",
    "      test_loss = test_loss / len(test_loader.sampler)\n",
    "      test_acc = test_correct / len(test_loader.sampler) * 100\n",
    "      print(\"Epoch:{}/{} AVG Training Loss:{:.3f} AVG Test Loss:{:.3f} AVG Training Acc {:.2f} % AVG Test Acc {:.2f} %\".format(epoch + 1,\n",
    "                                                                                                                              num_epochs,\n",
    "                                                                                                                              train_loss,\n",
    "                                                                                                                              test_loss,\n",
    "                                                                                                                              train_acc,\n",
    "                                                                                                                              test_acc))\n",
    "      history['train_loss'].append(train_loss)\n",
    "      history['test_loss'].append(test_loss)\n",
    "      history['train_acc'].append(train_acc)\n",
    "      history['test_acc'].append(test_acc)\n",
    "      foldperf['fold{}'.format(fold+1)] = history\n",
    "      torch.save(model,'k_cross_CNN.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of 10 fold cross validation\n",
      "Average Training Loss: 0.062 \t Average Test Loss: 0.040 \t Average Training Acc: 98.08 \t Average Test Acc:98.70\n",
      "Performance of 10 fold cross validation\n",
      "Average Training Loss: 0.063 \t Average Test Loss: 0.038 \t Average Training Acc: 98.05 \t Average Test Acc:98.81\n",
      "Performance of 10 fold cross validation\n",
      "Average Training Loss: 0.064 \t Average Test Loss: 0.039 \t Average Training Acc: 98.01 \t Average Test Acc:98.83\n",
      "Performance of 10 fold cross validation\n",
      "Average Training Loss: 0.064 \t Average Test Loss: 0.037 \t Average Training Acc: 98.01 \t Average Test Acc:98.84\n",
      "Performance of 10 fold cross validation\n",
      "Average Training Loss: 0.065 \t Average Test Loss: 0.038 \t Average Training Acc: 97.99 \t Average Test Acc:98.82\n",
      "Performance of 10 fold cross validation\n",
      "Average Training Loss: 0.065 \t Average Test Loss: 0.038 \t Average Training Acc: 97.98 \t Average Test Acc:98.84\n",
      "Performance of 10 fold cross validation\n",
      "Average Training Loss: 0.065 \t Average Test Loss: 0.037 \t Average Training Acc: 97.98 \t Average Test Acc:98.85\n",
      "Performance of 10 fold cross validation\n",
      "Average Training Loss: 0.065 \t Average Test Loss: 0.039 \t Average Training Acc: 97.98 \t Average Test Acc:98.83\n",
      "Performance of 10 fold cross validation\n",
      "Average Training Loss: 0.065 \t Average Test Loss: 0.039 \t Average Training Acc: 97.98 \t Average Test Acc:98.83\n",
      "Performance of 10 fold cross validation\n",
      "Average Training Loss: 0.065 \t Average Test Loss: 0.038 \t Average Training Acc: 97.98 \t Average Test Acc:98.84\n"
     ]
    }
   ],
   "source": [
    "testl_f,tl_f,testa_f,ta_f=[],[],[],[]\n",
    "k=10\n",
    "for f in range(1,k+1):\n",
    "  tl_f.append(np.mean(foldperf['fold{}'.format(f)]['train_loss']))\n",
    "  testl_f.append(np.mean(foldperf['fold{}'.format(f)]['test_loss']))\n",
    "  ta_f.append(np.mean(foldperf['fold{}'.format(f)]['train_acc']))\n",
    "  testa_f.append(np.mean(foldperf['fold{}'.format(f)]['test_acc']))\n",
    "  print('Performance of {} fold cross validation'.format(k))\n",
    "  print(\"Average Training Loss: {:.3f} \\t Average Test Loss: {:.3f} \\t Average Training Acc: {:.2f} \\t Average Test Acc:{:.2f}\".format(np.mean(tl_f),np.mean(testl_f),np.mean(ta_f),np.mean(testa_f)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
