{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import sys\n",
    "import random\n",
    "from sklearn.model_selection import KFold\n",
    "import math\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置GPU使用方式\n",
    "# 获取GPU列表\n",
    "gpus = [torch.cuda.device(i) for i in range(torch.cuda.device_count())]\n",
    "\n",
    "if gpus:\n",
    "    try:\n",
    "        # 设置每个GPU为增长式占用\n",
    "        for gpu in gpus:\n",
    "            torch.cuda.set_per_process_memory_fraction(1.0, gpu)  # 可根据需要调整占用比例\n",
    "    except RuntimeError as e:\n",
    "        # 打印异常\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FBCNet(nn.Module):\n",
    "    def __init__(self, m=32,C=30,Nc=2,T=200,Nb=9,w=50):\n",
    "        super(FBCNet, self).__init__()\n",
    "        self.dropout = 0.5\n",
    "        self.conv1 = nn.Conv2d(Nb, m*Nb, (C, 1), padding=0)\n",
    "        self.batchnorm1 = nn.BatchNorm2d(m*Nb, False)\n",
    "        self.fc1 = nn.Linear(12607488,Nc)\n",
    "        \n",
    "\n",
    "    def forward(self, x,w=50):\n",
    "        #Spatial convolution\n",
    "        x = self.conv1(x)\n",
    "        x = self.batchnorm1(x)\n",
    "        x = F.elu(x)\n",
    "        #Temporal Feature Extration\n",
    "        x1 = torch.var(x[:,:,:,0:w], dim=3, keepdim=True)\n",
    "        x2 = torch.var(x[:,:,:,w:2*w], dim=3, keepdim=True)\n",
    "        x3 = torch.var(x[:,:,:,2*w:3*w], dim=3, keepdim=True)\n",
    "        x4 = torch.var(x[:,:,:,3*w:4*w], dim=3, keepdim=True)\n",
    "        x=torch.cat((x1,x2,x3,x4),dim=3)\n",
    "        x = F.logsigmoid(x)\n",
    "        print('log',x.shape)\n",
    "        #   Classifier\n",
    "        x = torch.flatten(x)\n",
    "        print('faltten',x.shape)\n",
    "        x = self.fc1(x)  # 使用线性层\n",
    "        x = F.softmax(x)\n",
    "        print(x.shape)\n",
    "        return x\n",
    "\n",
    "    def apply_max_norm(self, max_norm=2.0):\n",
    "        torch.nn.utils.clip_grad_norm_(self.parameters(), max_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1650, 30, 200)\n",
      "(1650, 30, 200)\n"
     ]
    }
   ],
   "source": [
    "#导入数据\n",
    "#rest1\n",
    "datapath1=r'D:\\JQ_YJS\\过山车实验数据epochs转一个class（4）\\rest1_class.npy' \n",
    "data1=np.load(datapath1)\n",
    "print(data1.shape)\n",
    "#rest2\n",
    "datapath2=r'D:\\JQ_YJS\\过山车实验数据epochs转一个class（4）\\rest1_class.npy'\n",
    "data2=np.load(datapath2)\n",
    "print(data2.shape)\n",
    "data_all=np.concatenate((data1,data2),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#标签制作\n",
    "label_all = torch.cat([torch.zeros(10505), torch.ones(10505)]).long()  # 标签：前10505个为0，后10505个为1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold号: 1\n",
      "FBCNet(\n",
      "  (conv1): Conv2d(9, 288, kernel_size=(30, 1), stride=(1, 1))\n",
      "  (batchnorm1): BatchNorm2d(288, eps=False, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc1): Linear(in_features=12607488, out_features=2, bias=True)\n",
      ")\n",
      "开始训练!!\n",
      "训练批次输入数据形状: torch.Size([16, 30, 200])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FJQ\\AppData\\Local\\Temp\\ipykernel_24440\\2139316532.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_dataset = TensorDataset(torch.tensor(epoch_train, dtype=torch.float32), torch.tensor(label_train, dtype=torch.long))\n",
      "C:\\Users\\FJQ\\AppData\\Local\\Temp\\ipykernel_24440\\2139316532.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  val_dataset = TensorDataset(torch.tensor(epoch_val, dtype=torch.float32), torch.tensor(label_val, dtype=torch.long))\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [288, 9, 30, 1], expected input[1, 16, 30, 200] to have 9 channels, but got 16 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 57\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m训练批次输入数据形状: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minputs\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     56\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 57\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     58\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, targets)\n\u001b[0;32m     59\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32md:\\anaconda\\envs\\DL\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\anaconda\\envs\\DL\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[5], line 12\u001b[0m, in \u001b[0;36mFBCNet.forward\u001b[1;34m(self, x, w)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x,w\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m):\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;66;03m#Spatial convolution\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatchnorm1(x)\n\u001b[0;32m     14\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39melu(x)\n",
      "File \u001b[1;32md:\\anaconda\\envs\\DL\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\anaconda\\envs\\DL\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\anaconda\\envs\\DL\\lib\\site-packages\\torch\\nn\\modules\\conv.py:458\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    457\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 458\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\anaconda\\envs\\DL\\lib\\site-packages\\torch\\nn\\modules\\conv.py:454\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    452\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    453\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 454\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    455\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Given groups=1, weight of size [288, 9, 30, 1], expected input[1, 16, 30, 200] to have 9 channels, but got 16 channels instead"
     ]
    }
   ],
   "source": [
    "# 创建十折交叉验证\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# 保存结果的列表\n",
    "historys = []\n",
    "test_pred = []\n",
    "test_real = []\n",
    "accuracy, precision, recall, f1score = [], [], [], []\n",
    "batchsz = 16\n",
    "\n",
    "# 进行十折交叉验证\n",
    "for fold, (train_ind, test_ind) in enumerate(kfold.split(data_all, label_all)):\n",
    "    print('fold号:', fold + 1)\n",
    "\n",
    "    # 每一折验证前都要打乱训练集样本顺序\n",
    "    n = len(train_ind)\n",
    "    A = np.linspace(0, n - 1, n, dtype=int)\n",
    "    random.shuffle(A)\n",
    "\n",
    "    # 构建训练集、验证集、测试集\n",
    "    epoch_train = data_all[train_ind[A[:int(0.8 * n)]]]\n",
    "    epoch_val = data_all[train_ind[A[int(0.8 * n):]]]\n",
    "    epoch_test = data_all[test_ind]\n",
    "    label_train = label_all[train_ind[A[:int(0.8 * n)]]]\n",
    "    label_val = label_all[train_ind[A[int(0.8 * n):]]]\n",
    "    label_test = label_all[test_ind]\n",
    "\n",
    "    # 转换为Tensor并创建DataLoader\n",
    "    train_dataset = TensorDataset(torch.tensor(epoch_train, dtype=torch.float32), torch.tensor(label_train, dtype=torch.long))\n",
    "    val_dataset = TensorDataset(torch.tensor(epoch_val, dtype=torch.float32), torch.tensor(label_val, dtype=torch.long))\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batchsz, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batchsz, shuffle=False)\n",
    "\n",
    "    # 选择、创建模型\n",
    "    model = FBCNet()\n",
    "    print(model)\n",
    "\n",
    "    # 配置模型训练\n",
    "    criterion = nn.CrossEntropyLoss()  # 使用交叉熵损失\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "    # 开始训练模型\n",
    "    print('开始训练!!')\n",
    "    history = {'train_loss': [], 'val_loss': []}\n",
    "\n",
    "    for epoch in range(100):  # 训练100个epoch\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        # 训练阶段\n",
    "        for inputs, targets in train_loader:\n",
    "            \n",
    "            print(f\"训练批次输入数据形状: {inputs.shape}\")\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = running_loss / len(train_loader)\n",
    "        history['train_loss'].append(avg_train_loss)\n",
    "\n",
    "        # 验证阶段\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in val_loader:\n",
    "                print('啦啦啦',input.shape)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        history['val_loss'].append(avg_val_loss)\n",
    "\n",
    "    # 保存训练记录\n",
    "    historys.append(history)\n",
    "\n",
    "    # 计算、保存测试结果\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        pred_test = model(torch.tensor(epoch_test, dtype=torch.float32))\n",
    "        pred_test = torch.argmax(pred_test, dim=1).numpy()\n",
    "\n",
    "    # 保存预测结果和真实结果\n",
    "    test_pred.append(pred_test)\n",
    "    test_real.append(label_test)\n",
    "\n",
    "    # 计算准确率，精确率，召回率，F1评分\n",
    "    acc = accuracy_score(label_test, pred_test)\n",
    "    pre = precision_score(label_test, pred_test, average='macro')\n",
    "    rec = recall_score(label_test, pred_test, average='macro')\n",
    "    f1 = f1_score(label_test, pred_test, average='macro')\n",
    "    \n",
    "    accuracy.append(acc)\n",
    "    precision.append(pre)\n",
    "    recall.append(rec)\n",
    "    f1score.append(f1)\n",
    "\n",
    "    print(f\"$$ 测试集准确率为 accuracy: {acc}\")\n",
    "    print(f\"$$ 测试集精确率为 precision: {pre}\")\n",
    "    print(f\"$$ 测试集召回率为 recall: {rec}\")\n",
    "    print(f\"$$ 测试集 F1 评分为 f1_score: {f1}\")\n",
    "\n",
    "# 将每一折 history 中误差结果保存（训练集和测试集，用于反映训练过程）    \n",
    "loss_train = []\n",
    "loss_val = []\n",
    "for history_s in historys:\n",
    "    loss_val.append(history_s['val_loss'])\n",
    "    loss_train.append(history_s['train_loss'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
