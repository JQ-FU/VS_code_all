{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 60000\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader,TensorDataset,random_split,SubsetRandomSampler, ConcatDataset\n",
    "from torch.nn import functional as F\n",
    "import torchvision\n",
    "from torchvision import datasets,transforms\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# 加载 MNIST 数据集\n",
    "train_dataset = torchvision.datasets.MNIST('classifier_data', train=True, download=True)\n",
    "test_dataset = torchvision.datasets.MNIST('classifier_data', train=False, download=True)\n",
    "\n",
    "# 定义数据转换\n",
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# 应用转换到数据集\n",
    "train_dataset.transform = transform\n",
    "test_dataset.transform = transform\n",
    "\n",
    "# 获取训练数据的样本数\n",
    "m = len(train_dataset)\n",
    "\n",
    "# 示例打印样本数\n",
    "print(f'Number of training samples: {m}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self,h1=96):\n",
    "        # We optimize dropout rate in a convolutional neural network.\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5, stride=1, padding=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5, stride=1, padding=2)\n",
    "        self.drop1=nn.Dropout2d(p=0.5)\n",
    "        self.fc1 = nn.Linear(32 * 7 * 7, h1)\n",
    "        self.drop2=nn.Dropout2d(p=0.1)\n",
    "        self.fc2 = nn.Linear(h1, 10)\n",
    "    def forward(self, x):\n",
    "            x = F.relu(F.max_pool2d(self.conv1(x),kernel_size = 2))\n",
    "            x = F.relu(F.max_pool2d(self.conv2(x),kernel_size = 2))\n",
    "            x = self.drop1(x)\n",
    "            x = x.view(x.size(0),-1)\n",
    "            \n",
    "            x = F.relu(self.fc1(x))\n",
    "            x = self.drop2(x)\n",
    "            x = self.fc2(x)\n",
    "            #print('数值',x)\n",
    "            return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.manual_seed(42)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "dataset = ConcatDataset([train_dataset, test_dataset])\n",
    "num_epochs=10\n",
    "batch_size=128\n",
    "k=10\n",
    "splits=KFold(n_splits=k,shuffle=True,random_state=42)\n",
    "foldperf={} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model,device,dataloader,loss_fn,optimizer):\n",
    "  train_loss,train_correct=0.0,0\n",
    "  model.train()\n",
    "  for images, labels in dataloader:\n",
    "    images,labels = images.to(device),labels.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    output = model(images)\n",
    "    \n",
    "   \n",
    "    loss = loss_fn(output,labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    train_loss += loss.item() * images.size(0)\n",
    "    scores, predictions = torch.max(output.data, 1)\n",
    "    \n",
    "    train_correct += (predictions == labels).sum().item()\n",
    "  return train_loss,train_correct\n",
    "def valid_epoch(model,device,dataloader,loss_fn):\n",
    "        valid_loss, val_correct = 0.0, 0\n",
    "        model.eval()\n",
    "        for images, labels in dataloader:\n",
    "            images,labels = images.to(device),labels.to(device)\n",
    "            output = model(images)\n",
    "            loss=loss_fn(output,labels)\n",
    "            valid_loss+=loss.item()*images.size(0)\n",
    "            scores, predictions = torch.max(output.data,1)\n",
    "            val_correct+=(predictions == labels).sum().item()\n",
    "        return valid_loss,val_correct "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\DL\\lib\\site-packages\\torch\\nn\\functional.py:1374: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss type: <class 'float'>, train_correct type: <class 'int'>\n",
      "Epoch:1/10 AVG Training Loss:0.228 AVG Test Loss:0.072 AVG Training Acc 93.06 % AVG Test Acc 97.80 %\n",
      "train_loss type: <class 'float'>, train_correct type: <class 'int'>\n",
      "Epoch:2/10 AVG Training Loss:0.075 AVG Test Loss:0.046 AVG Training Acc 97.72 % AVG Test Acc 98.29 %\n",
      "train_loss type: <class 'float'>, train_correct type: <class 'int'>\n",
      "Epoch:3/10 AVG Training Loss:0.059 AVG Test Loss:0.046 AVG Training Acc 98.22 % AVG Test Acc 98.56 %\n",
      "train_loss type: <class 'float'>, train_correct type: <class 'int'>\n",
      "Epoch:4/10 AVG Training Loss:0.051 AVG Test Loss:0.035 AVG Training Acc 98.47 % AVG Test Acc 98.76 %\n",
      "train_loss type: <class 'float'>, train_correct type: <class 'int'>\n",
      "Epoch:5/10 AVG Training Loss:0.041 AVG Test Loss:0.032 AVG Training Acc 98.72 % AVG Test Acc 99.03 %\n",
      "train_loss type: <class 'float'>, train_correct type: <class 'int'>\n",
      "Epoch:6/10 AVG Training Loss:0.040 AVG Test Loss:0.032 AVG Training Acc 98.73 % AVG Test Acc 98.91 %\n",
      "train_loss type: <class 'float'>, train_correct type: <class 'int'>\n",
      "Epoch:7/10 AVG Training Loss:0.036 AVG Test Loss:0.029 AVG Training Acc 98.86 % AVG Test Acc 99.06 %\n",
      "train_loss type: <class 'float'>, train_correct type: <class 'int'>\n",
      "Epoch:8/10 AVG Training Loss:0.033 AVG Test Loss:0.037 AVG Training Acc 98.95 % AVG Test Acc 98.86 %\n",
      "train_loss type: <class 'float'>, train_correct type: <class 'int'>\n",
      "Epoch:9/10 AVG Training Loss:0.031 AVG Test Loss:0.034 AVG Training Acc 98.97 % AVG Test Acc 98.93 %\n",
      "train_loss type: <class 'float'>, train_correct type: <class 'int'>\n",
      "Epoch:10/10 AVG Training Loss:0.027 AVG Test Loss:0.031 AVG Training Acc 99.16 % AVG Test Acc 99.06 %\n",
      "Fold 2\n"
     ]
    }
   ],
   "source": [
    "for fold, (train_idx,val_idx) in enumerate(splits.split(np.arange(len(dataset)))):\n",
    "  print('Fold {}'.format(fold + 1))\n",
    "  train_sampler = SubsetRandomSampler(train_idx)\n",
    "  test_sampler = SubsetRandomSampler(val_idx)\n",
    "  train_loader = DataLoader(dataset, batch_size=batch_size, sampler=train_sampler)\n",
    "  test_loader = DataLoader(dataset, batch_size=batch_size, sampler=test_sampler)\n",
    "\n",
    "  \n",
    "  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "  model = ConvNet()\n",
    "  model.to(device)\n",
    "  optimizer = optim.Adam(model.parameters(), lr=0.002)\n",
    "  history = {'train_loss': [], 'test_loss': [],'train_acc':[],'test_acc':[]}\n",
    "  for epoch in range(num_epochs):\n",
    "      train_loss, train_correct=train_epoch(model,device,train_loader,criterion,optimizer)\n",
    "      print(f'train_loss type: {type(train_loss)}, train_correct type: {type(train_correct)}')\n",
    "      test_loss, test_correct=valid_epoch(model,device,test_loader,criterion)\n",
    "      train_loss = train_loss / len(train_loader.sampler)\n",
    "      train_acc = train_correct / len(train_loader.sampler) * 100\n",
    "      test_loss = test_loss / len(test_loader.sampler)\n",
    "      test_acc = test_correct / len(test_loader.sampler) * 100\n",
    "      print(\"Epoch:{}/{} AVG Training Loss:{:.3f} AVG Test Loss:{:.3f} AVG Training Acc {:.2f} % AVG Test Acc {:.2f} %\".format(epoch + 1,\n",
    "                                                                                                                              num_epochs,\n",
    "                                                                                                                              train_loss,\n",
    "                                                                                                                              test_loss,\n",
    "                                                                                                                              train_acc,\n",
    "                                                                                                                              test_acc))\n",
    "      history['train_loss'].append(train_loss)\n",
    "      history['test_loss'].append(test_loss)\n",
    "      history['train_acc'].append(train_acc)\n",
    "      history['test_acc'].append(test_acc)\n",
    "      foldperf['fold{}'.format(fold+1)] = history\n",
    "      torch.save(model,'k_cross_CNN.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of 10 fold cross validation\n",
      "Average Training Loss: 0.062 \t Average Test Loss: 0.040 \t Average Training Acc: 98.08 \t Average Test Acc:98.70\n",
      "Performance of 10 fold cross validation\n",
      "Average Training Loss: 0.063 \t Average Test Loss: 0.038 \t Average Training Acc: 98.05 \t Average Test Acc:98.81\n",
      "Performance of 10 fold cross validation\n",
      "Average Training Loss: 0.064 \t Average Test Loss: 0.039 \t Average Training Acc: 98.01 \t Average Test Acc:98.83\n",
      "Performance of 10 fold cross validation\n",
      "Average Training Loss: 0.064 \t Average Test Loss: 0.037 \t Average Training Acc: 98.01 \t Average Test Acc:98.84\n",
      "Performance of 10 fold cross validation\n",
      "Average Training Loss: 0.065 \t Average Test Loss: 0.038 \t Average Training Acc: 97.99 \t Average Test Acc:98.82\n",
      "Performance of 10 fold cross validation\n",
      "Average Training Loss: 0.065 \t Average Test Loss: 0.038 \t Average Training Acc: 97.98 \t Average Test Acc:98.84\n",
      "Performance of 10 fold cross validation\n",
      "Average Training Loss: 0.065 \t Average Test Loss: 0.037 \t Average Training Acc: 97.98 \t Average Test Acc:98.85\n",
      "Performance of 10 fold cross validation\n",
      "Average Training Loss: 0.065 \t Average Test Loss: 0.039 \t Average Training Acc: 97.98 \t Average Test Acc:98.83\n",
      "Performance of 10 fold cross validation\n",
      "Average Training Loss: 0.065 \t Average Test Loss: 0.039 \t Average Training Acc: 97.98 \t Average Test Acc:98.83\n",
      "Performance of 10 fold cross validation\n",
      "Average Training Loss: 0.065 \t Average Test Loss: 0.038 \t Average Training Acc: 97.98 \t Average Test Acc:98.84\n"
     ]
    }
   ],
   "source": [
    "testl_f,tl_f,testa_f,ta_f=[],[],[],[]\n",
    "k=10\n",
    "for f in range(1,k+1):\n",
    "  tl_f.append(np.mean(foldperf['fold{}'.format(f)]['train_loss']))\n",
    "  testl_f.append(np.mean(foldperf['fold{}'.format(f)]['test_loss']))\n",
    "  ta_f.append(np.mean(foldperf['fold{}'.format(f)]['train_acc']))\n",
    "  testa_f.append(np.mean(foldperf['fold{}'.format(f)]['test_acc']))\n",
    "  print('Performance of {} fold cross validation'.format(k))\n",
    "  print(\"Average Training Loss: {:.3f} \\t Average Test Loss: {:.3f} \\t Average Training Acc: {:.2f} \\t Average Test Acc:{:.2f}\".format(np.mean(tl_f),np.mean(testl_f),np.mean(ta_f),np.mean(testa_f)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
